import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from datetime import datetime

# 1. í˜ì´ì§€ ì„¤ì • ë° ë””ìì¸
st.set_page_config(page_title="ì— ë²„ AI ì§€ë°°ì¸ v6.0", layout="wide")

# ì§ê´€ì„±ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë§ì¶¤í˜• CSS
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    .stMetric { background-color: #ffffff; padding: 15px; border-radius: 12px; border: 1px solid #e9ecef; box-shadow: 0 4px 6px rgba(0,0,0,0.02); }
    div[data-testid="stMetricValue"] { font-size: 28px; font-weight: 700; color: #1a1c1e; }
    .action-card { 
        background-color: #f0f7ff; border-left: 5px solid #007bff; padding: 20px; 
        border-radius: 8px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .parity-alert { 
        background-color: #fff5f5; border-left: 5px solid #ff4b4b; padding: 15px; 
        border-radius: 8px; margin-bottom: 10px; color: #d32f2f; font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ¨ ì— ë²„ 7ëŒ€ í”Œë«í¼ í†µí•© AI ì§€ë°°ì¸ v6.0")
st.caption("AI ì „ëµ ì œì•ˆ & ë•¡ì²˜ë¦¬ ì¶”ì  í†µí•© ì‹œìŠ¤í…œ")

# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì •ë°€ ì •ì œ í•¨ìˆ˜
SHEET_ID = "1gTbVR4lfmCVa2zoXwsOqjm1VaCy9bdGWYJGaifckqrs"
URL = f"https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv"

@st.cache_data(ttl=5) # 5ì´ˆ ì‹¤ì‹œê°„ ê°±ì‹ 
def load_data():
    try:
        data = pd.read_csv(URL, encoding='utf-8-sig')
        # [ë°ì´í„° ì •ë°€ ì •ì œ] ë§¤ì¹­ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ëª¨ë“  ê³µë°± ì œê±°
        data['í˜¸í…”ëª…'] = data['í˜¸í…”ëª…'].astype(str).str.replace(" ", "").str.strip()
        data['ë‚ ì§œ'] = data['ë‚ ì§œ'].astype(str).str.replace(" ", "").str.strip()
        data['ê°ì‹¤íƒ€ì…'] = data['ê°ì‹¤íƒ€ì…'].astype(str).str.strip()
        
        # ê°€ê²© ìˆ«ì ë³€í™˜
        data['ê°€ê²©'] = pd.to_numeric(data['ê°€ê²©'].astype(str).str.replace(',', '').str.replace('ì›', ''), errors='coerce')
        
        # ìˆ˜ì§‘ì‹œê°„ ë° íˆ¬ìˆ™ì¼ ë³€í™˜
        data['ìˆ˜ì§‘ì‹œê°„'] = pd.to_datetime(data['ìˆ˜ì§‘ì‹œê°„'], errors='coerce')
        data['íˆ¬ìˆ™ì¼'] = pd.to_datetime(data['ë‚ ì§œ'], errors='coerce')
        
        # ë¦¬ë“œíƒ€ì„ ê³„ì‚° (íˆ¬ìˆ™ì¼ - ìˆ˜ì§‘ì¼)
        data['ë¦¬ë“œíƒ€ì„'] = (data['íˆ¬ìˆ™ì¼'] - data['ìˆ˜ì§‘ì‹œê°„']).dt.days
        
        # í•„ìˆ˜ ë°ì´í„° ëˆ„ë½ ì œê±° ë° 150ë§Œì› ìƒí•œ í•„í„°
        data = data.dropna(subset=['í˜¸í…”ëª…', 'ê°€ê²©', 'ë‚ ì§œ'])
        data = data[data['ê°€ê²©'] < 1500000]
        
        return data
    except Exception as e:
        return pd.DataFrame()

try:
    df = load_data()
    
    if not df.empty:
        # --- [ì‚¬ì´ë“œë°” í•„í„° êµ¬ì—­] ---
        st.sidebar.header("ğŸ” ë¶„ì„ í•„í„° ì„¤ì •")
        
        # 1. ë‚ ì§œ ë©€í‹° ì„ íƒ
        all_dates = sorted(df['ë‚ ì§œ'].unique())
        selected_dates = st.sidebar.multiselect("ğŸ“… ë¶„ì„ ëŒ€ìƒ íˆ¬ìˆ™ì¼ ì„ íƒ", options=all_dates, default=[all_dates[-1]] if all_dates else [])
        
        # 2. 13ê°œ ì „ì²´ í˜¸í…” ë¦¬ìŠ¤íŠ¸ ê³ ì •
        target_list = ["ì— ë²„í“¨ì–´í", "ê·¸ëœë“œí•˜ì–íŠ¸", "íŒŒë¥´ë‚˜ìŠ¤", "ì‹ ë¼í˜¸í…”", "ë¡¯ë°í˜¸í…”", "ì‹ ë¼ìŠ¤í…Œì´", "í•´ë¹„ì¹˜", "ì‹ í™”ë©”ë¦¬ì–´íŠ¸", "íˆë“ í´ë¦¬í”„", "ë”ì‹œì—ë‚˜", "ì¡°ì„ íìŠ¤ìœ„íŠ¸", "ë©”ì¢…ê¸€ë˜ë“œ", "ê·¸ëœë“œì¡°ì„ ì œì£¼"]
        all_hotels = sorted(df['í˜¸í…”ëª…'].unique())
        selected_hotels = st.sidebar.multiselect("ğŸ¨ ë¶„ì„ ëŒ€ìƒ í˜¸í…” ì„ íƒ", options=all_hotels, default=[h for h in target_list if h in all_hotels])

        # 3. ì— ë²„ í•µì‹¬ ê°ì‹¤ í•„í„° ê³ ì •
        st.sidebar.markdown("---")
        st.sidebar.header("ğŸ¯ ì— ë²„ ì „ìš© í•µì‹¬ ê°ì‹¤")
        ember_core_rooms = ["ê·¸ë¦°ë°¸ë¦¬ ë””ëŸ­ìŠ¤ ë”ë¸”", "í ì— ë²„ íŠ¸ìœˆ", "í íŒŒì¸ ë”ë¸”"]
        existing_rooms = [r for r in ember_core_rooms if r in df['ê°ì‹¤íƒ€ì…'].unique()]
        selected_core_rooms = st.sidebar.multiselect("ğŸ›ï¸ ì— ë²„ ë¶„ì„ ê°ì‹¤ ì„ íƒ", options=existing_rooms, default=existing_rooms)

        # 4. í•„í„°ë§ ì ìš©
        f_df = df[(df['ë‚ ì§œ'].isin(selected_dates)) & (df['í˜¸í…”ëª…'].isin(selected_hotels))]
        if selected_core_rooms:
            # ì— ë²„ëŠ” ì„ íƒëœ ê°ì‹¤ë§Œ, íƒ€ í˜¸í…”ì€ ì „ì²´ ìœ ì§€
            f_df = f_df[ (~f_df['í˜¸í…”ëª…'].str.contains("ì— ë²„")) | (f_df['ê°ì‹¤íƒ€ì…'].isin(selected_core_rooms)) ]

        # ì— ë²„ ë°ì´í„° ì •ë°€ ì¶”ì¶œ
        amber_in_filter = f_df[f_df['í˜¸í…”ëª…'].str.contains("ì— ë²„", na=False)]
        amber_min_val = amber_in_filter['ê°€ê²©'].min() if not amber_in_filter.empty else 0

        # ---------------------------------------------------------
        # ğŸ’¡ [í•µì‹¬ ì‹ ê·œ ê¸°ëŠ¥ 1] AI ì˜¤ëŠ˜ì˜ í•œ ìˆ˜ (Daily Action Plan)
        # ---------------------------------------------------------
        st.subheader("ğŸ’¡ AI ì§€ë°°ì¸ ì˜¤ëŠ˜ì˜ ì „ëµ ì œì•ˆ")
        with st.container():
            st.markdown('<div class="action-card">', unsafe_allow_html=True)
            col_a, col_b = st.columns(2)
            with col_a:
                st.write("ğŸš© **ê¸´ê¸‰ ì ê²€ ë° ì¡°ì¹˜**")
                # íŒŒë¦¬í‹° ê²½ë³´ ìœ ë¬´ í™•ì¸
                parity_issue = False
                if not amber_in_filter.empty:
                    for (date, room), group in amber_in_filter.groupby(['ë‚ ì§œ', 'ê°ì‹¤íƒ€ì…']):
                        if group['ê°€ê²©'].min() < group['ê°€ê²©'].max() - 5000: parity_issue = True
                
                if parity_issue: st.write("- ğŸš¨ í˜„ì¬ ì¼ë¶€ ì±„ë„ì—ì„œ **ê°€ê²© ì—­ì „**ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ í™•ì¸í•˜ì‹­ì‹œì˜¤.")
                else: st.write("- âœ… ëª¨ë“  ì±„ë„ì˜ ê°€ê²© íŒŒë¦¬í‹°ê°€ ê¹¨ë—í•©ë‹ˆë‹¤.")

                # ë•¡ì²˜ë¦¬ í˜¸í…” ê°ì§€
                dumping_list = []
                for h in selected_hotels:
                    if "ì— ë²„" in h: continue
                    h_data = f_df[f_df['í˜¸í…”ëª…'] == h]
                    if not h_data.empty and h_data['ë¦¬ë“œíƒ€ì„'].min() <= 3:
                        recent_p = h_data[h_data['ë¦¬ë“œíƒ€ì„'] <= 3]['ê°€ê²©'].mean()
                        prev_p = h_data[h_data['ë¦¬ë“œíƒ€ì„'] > 7]['ê°€ê²©'].mean()
                        if recent_p < prev_p * 0.85: dumping_list.append(h)
                
                if dumping_list: st.write(f"- ğŸš¨ **{', '.join(dumping_list)}**ê°€ íˆ¬ìˆ™ ì„ë°• ë•¡ì²˜ë¦¬ë¥¼ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.")
                else: st.write("- ğŸ•Šï¸ ê²½ìŸì‚¬ë“¤ì˜ ê¸‰ê²©í•œ íˆ¬ë§¤ ì§•í›„ëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            with col_b:
                st.write("ğŸ“ˆ **ë§¤ì¶œ ê·¹ëŒ€í™” ì œì•ˆ**")
                if amber_min_val > 0:
                    comp_min = f_df[~f_df['í˜¸í…”ëª…'].str.contains("ì— ë²„")]['ê°€ê²©'].min() if not f_df[~f_df['í˜¸í…”ëª…'].str.contains("ì— ë²„")].empty else 0
                    if amber_min_val > comp_min + 50000: st.write("- ğŸ“‰ ì‹œì¥ ëŒ€ë¹„ ì— ë²„ê°€ ê³ ê°€ì…ë‹ˆë‹¤. ì†Œí­ ì¸í•˜ë¡œ ì˜ˆì•½ ì„ ì ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    elif amber_min_val < comp_min - 30000: st.write("- ğŸ’° ì— ë²„ê°€ ì••ë„ì  ì €ê°€ì…ë‹ˆë‹¤! ë§Œ ì› ì •ë„ ì¸ìƒí•˜ì—¬ ìˆ˜ìµë¥ ì„ ë†’ì´ì‹­ì‹œì˜¤.")
                    else: st.write("- âœ¨ í˜„ì¬ ì ì • ì‹œì¥ê°€ë¥¼ ìœ ì§€ ì¤‘ì…ë‹ˆë‹¤. í˜„ ìƒíƒœë¥¼ ìœ ì§€í•˜ì‹­ì‹œì˜¤.")
            st.markdown('</div>', unsafe_allow_html=True)

        # ---------------------------------------------------------
        # ğŸŸ¢ ì‹¤ì‹œê°„ ê°€ê²© ì—­ì „ íƒì§€ (Parity Check)
        # ---------------------------------------------------------
        st.subheader("âš ï¸ ì‹¤ì‹œê°„ ê°€ê²© ì—­ì „ ìƒì„¸ ì•Œë¦¼")
        if not amber_in_filter.empty:
            parity_alerts = []
            for (date, room), group in amber_in_filter.groupby(['ë‚ ì§œ', 'ê°ì‹¤íƒ€ì…']):
                official_price = group['ê°€ê²©'].max()
                broken_channels = group[group['ê°€ê²©'] < official_price]
                for _, row in broken_channels.iterrows():
                    gap = official_price - row['ê°€ê²©']
                    if gap > 5000:
                        parity_alerts.append(f"ğŸš¨ **[ê°€ê²© ë¬´ë„ˆì§]** {row['ë‚ ì§œ']} | {row['ê°ì‹¤íƒ€ì…']} | **{row['íŒë§¤ì²˜']}** ê°€ ê¸°ì¤€ë³´ë‹¤ **{gap:,.0f}ì›** ë‚®ìŒ!")
            
            if parity_alerts:
                for alert in parity_alerts[:5]: st.markdown(f'<div class="parity-alert">{alert}</div>', unsafe_allow_html=True)
            else: st.success("âœ… ê°€ê²© íŒŒë¦¬í‹° ì •ìƒ")

        # ---------------------------------------------------------
        # ğŸ“‰ [í•µì‹¬ ì‹ ê·œ ê¸°ëŠ¥ 2] ê²½ìŸì‚¬ ë•¡ì²˜ë¦¬ ì¶”ì  (Booking Pace)
        # ---------------------------------------------------------
        st.subheader("ğŸ“‰ íˆ¬ìˆ™ ì„ë°• ë•¡ì²˜ë¦¬ ì¶”ì  (Lead-time Analysis)")
        pace_trend = f_df.groupby(['ë¦¬ë“œíƒ€ì„', 'í˜¸í…”ëª…'])['ê°€ê²©'].min().reset_index()
        fig_pace = px.line(pace_trend, x='ë¦¬ë“œíƒ€ì„', y='ê°€ê²©', color='í˜¸í…”ëª…', markers=True, title="ë¦¬ë“œíƒ€ì„ë³„ ìµœì €ê°€ ì¶”ì´ (ì˜¤ë¥¸ìª½ì´ íˆ¬ìˆ™ì¼ ì„ë°•)")
        fig_pace.update_xaxes(autorange="reversed")
        st.plotly_chart(fig_pace, use_container_width=True)

        st.markdown("---")

        # 1. ì§€í‘œ ìš”ì•½
        st.subheader("ğŸš€ ì‹¤ì‹œê°„ ì‹œì¥ ìš”ì•½")
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("ì— ë²„ ìµœì €ê°€", f"{amber_min_val:,.0f}ì›" if amber_min_val > 0 else "ë°ì´í„° ì—†ìŒ")
        m2.metric("ì‹œì¥ ì „ì²´ ìµœì €ê°€", f"{f_df['ê°€ê²©'].min():,.0f}ì›" if not f_df.empty else "0ì›")
        m3.metric("ì‹œì¥ í‰ê· ê°€", f"{f_df['ê°€ê²©'].mean():,.0f}ì›" if not f_df.empty else "0ì›")
        m4.metric("í™œì„± 1ìœ„ ì±„ë„", f_df['íŒë§¤ì²˜'].value_counts().idxmax() if not f_df.empty else "ì—†ìŒ")

        # 2. ì‹ í˜¸ë“± ë§¤íŠ¸ë¦­ìŠ¤
        st.subheader("ğŸš¦ ì¼ìë³„ í˜¸í…” ìµœì €ê°€ ë§¤íŠ¸ë¦­ìŠ¤")
        if not f_df.empty:
            pivot_df = f_df.groupby(['í˜¸í…”ëª…', 'ë‚ ì§œ'])['ê°€ê²©'].min().unstack()
            def color_signal(val):
                if pd.isna(val) or amber_min_val == 0: return ''
                if val < amber_min_val - 30000: return 'background-color: #ffcccc; color: #d32f2f;'
                if val < amber_min_val: return 'background-color: #fff3cd;'
                return 'background-color: #d4edda;'
            st.dataframe(pivot_df.style.format("{:,.0f}ì›", na_rep="-").applymap(color_signal), use_container_width=True)

        # 3. ì— ë²„ í•µì‹¬ ê°ì‹¤ íˆíŠ¸ë§µ
        st.subheader("ğŸ’ ì— ë²„ í•µì‹¬ ê°ì‹¤ë³„/ì±„ë„ë³„ ìµœì €ê°€ ë¶„í¬ (Heatmap)")
        if not amber_in_filter.empty:
            amber_pivot = amber_in_filter.pivot_table(index='ê°ì‹¤íƒ€ì…', columns='íŒë§¤ì²˜', values='ê°€ê²©', aggfunc='min')
            st.plotly_chart(px.imshow(amber_pivot, text_auto=',.0f', color_continuous_scale='RdYlGn_r', aspect="auto"), use_container_width=True)

        # 4. ë‚ ì§œë³„ ì „ìˆ˜ ì¶”ì  ê·¸ë˜í”„
        st.subheader("ğŸ“Š ë‚ ì§œë³„ ì „ìˆ˜ ì¶”ì  ê·¸ë˜í”„")
        for date in selected_dates:
            d_df = f_df[f_df['ë‚ ì§œ'] == date].sort_values('ìˆ˜ì§‘ì‹œê°„')
            if not d_df.empty:
                st.plotly_chart(px.line(d_df, x='ìˆ˜ì§‘ì‹œê°„', y='ê°€ê²©', color='í˜¸í…”ëª…', markers=True, title=f"ğŸ“… {date} íˆ¬ìˆ™ì¼ ì‹¤ì‹œê°„ ê°€ê²© ì¶”ì´"), use_container_width=True)

        # 5. ê°€ê²© ì¡°ì • ì‹œë®¬ë ˆì´í„°
        st.markdown("---")
        st.subheader("ğŸ¯ ì— ë²„ ê°€ê²© ì¡°ì • ì‹œë®¬ë ˆì´í„°")
        if amber_min_val > 0:
            s1, s2 = st.columns([1, 2])
            with s1:
                delta = st.slider("ê°€ê²©ì„ ì¡°ì •í•´ë³´ì„¸ìš” (ì›)", -150000, 150000, 0, 5000)
                sim_p = amber_min_val + delta
                st.write(f"ğŸ“ˆ **ì¡°ì • í›„ ì˜ˆìƒê°€: {sim_p:,.0f}ì›**")
            comp_p = f_df[~f_df['í˜¸í…”ëª…'].str.contains("ì— ë²„")]['ê°€ê²©'].values
            if len(comp_p) > 0:
                comb = np.append(comp_p, sim_p); comb.sort()
                rank = np.where(comb == sim_p)[0][0] + 1
                st.write(f"ğŸ† ì˜ˆìƒ ì‹œì¥ ìˆœìœ„: **{len(comb)}ê°œ ì¤‘ {rank}ìœ„**")
                st.progress((len(comb) - rank + 1) / len(comb))

        with st.expander("ğŸ“‹ ìƒì„¸ ë¡œê·¸ ë³´ê¸°"):
            st.dataframe(f_df.sort_values(['ë‚ ì§œ', 'ìˆ˜ì§‘ì‹œê°„'], ascending=[True, False]), use_container_width=True, hide_index=True)

except Exception as e:
    st.error(f"ëŒ€ì‹œë³´ë“œ ì—ëŸ¬ ë°œìƒ: {e}")
